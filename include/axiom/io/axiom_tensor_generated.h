// automatically generated by the FlatBuffers compiler, do not modify

#ifndef FLATBUFFERS_GENERATED_AXIOMTENSOR_AXIOM_IO_FB_H_
#define FLATBUFFERS_GENERATED_AXIOMTENSOR_AXIOM_IO_FB_H_

#include "flatbuffers/flatbuffers.h"

// Ensure the included flatbuffers.h is the same version as when this file was
// generated, otherwise it may not be compatible.
static_assert(FLATBUFFERS_VERSION_MAJOR == 25 &&
                  FLATBUFFERS_VERSION_MINOR == 12 &&
                  FLATBUFFERS_VERSION_REVISION == 19,
              "Non-compatible flatbuffers version included");

namespace axiom {
namespace io {
namespace fb {

struct TensorData;
struct TensorDataBuilder;

struct TensorArchive;
struct TensorArchiveBuilder;

enum DType : int8_t {
    DType_Bool = 0,
    DType_Int8 = 1,
    DType_Int16 = 2,
    DType_Int32 = 3,
    DType_Int64 = 4,
    DType_UInt8 = 5,
    DType_UInt16 = 6,
    DType_UInt32 = 7,
    DType_UInt64 = 8,
    DType_Float16 = 9,
    DType_Float32 = 10,
    DType_Float64 = 11,
    DType_Complex64 = 12,
    DType_Complex128 = 13,
    DType_MIN = DType_Bool,
    DType_MAX = DType_Complex128
};

inline const DType (&EnumValuesDType())[14] {
    static const DType values[] = {
        DType_Bool,      DType_Int8,      DType_Int16,   DType_Int32,
        DType_Int64,     DType_UInt8,     DType_UInt16,  DType_UInt32,
        DType_UInt64,    DType_Float16,   DType_Float32, DType_Float64,
        DType_Complex64, DType_Complex128};
    return values;
}

inline const char *const *EnumNamesDType() {
    static const char *const names[15] = {
        "Bool",    "Int8",    "Int16",     "Int32",      "Int64",
        "UInt8",   "UInt16",  "UInt32",    "UInt64",     "Float16",
        "Float32", "Float64", "Complex64", "Complex128", nullptr};
    return names;
}

inline const char *EnumNameDType(DType e) {
    if (::flatbuffers::IsOutRange(e, DType_Bool, DType_Complex128))
        return "";
    const size_t index = static_cast<size_t>(e);
    return EnumNamesDType()[index];
}

enum MemoryOrder : int8_t {
    MemoryOrder_RowMajor = 0,
    MemoryOrder_ColMajor = 1,
    MemoryOrder_MIN = MemoryOrder_RowMajor,
    MemoryOrder_MAX = MemoryOrder_ColMajor
};

inline const MemoryOrder (&EnumValuesMemoryOrder())[2] {
    static const MemoryOrder values[] = {MemoryOrder_RowMajor,
                                         MemoryOrder_ColMajor};
    return values;
}

inline const char *const *EnumNamesMemoryOrder() {
    static const char *const names[3] = {"RowMajor", "ColMajor", nullptr};
    return names;
}

inline const char *EnumNameMemoryOrder(MemoryOrder e) {
    if (::flatbuffers::IsOutRange(e, MemoryOrder_RowMajor,
                                  MemoryOrder_ColMajor))
        return "";
    const size_t index = static_cast<size_t>(e);
    return EnumNamesMemoryOrder()[index];
}

struct TensorData FLATBUFFERS_FINAL_CLASS : private ::flatbuffers::Table {
    typedef TensorDataBuilder Builder;
    enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
        VT_NAME = 4,
        VT_DTYPE = 6,
        VT_SHAPE = 8,
        VT_MEMORY_ORDER = 10,
        VT_DATA = 12
    };
    const ::flatbuffers::String *name() const {
        return GetPointer<const ::flatbuffers::String *>(VT_NAME);
    }
    axiom::io::fb::DType dtype() const {
        return static_cast<axiom::io::fb::DType>(GetField<int8_t>(VT_DTYPE, 0));
    }
    const ::flatbuffers::Vector<uint64_t> *shape() const {
        return GetPointer<const ::flatbuffers::Vector<uint64_t> *>(VT_SHAPE);
    }
    axiom::io::fb::MemoryOrder memory_order() const {
        return static_cast<axiom::io::fb::MemoryOrder>(
            GetField<int8_t>(VT_MEMORY_ORDER, 0));
    }
    const ::flatbuffers::Vector<uint8_t> *data() const {
        return GetPointer<const ::flatbuffers::Vector<uint8_t> *>(VT_DATA);
    }
    template <bool B = false>
    bool Verify(::flatbuffers::VerifierTemplate<B> &verifier) const {
        return VerifyTableStart(verifier) && VerifyOffset(verifier, VT_NAME) &&
               verifier.VerifyString(name()) &&
               VerifyField<int8_t>(verifier, VT_DTYPE, 1) &&
               VerifyOffset(verifier, VT_SHAPE) &&
               verifier.VerifyVector(shape()) &&
               VerifyField<int8_t>(verifier, VT_MEMORY_ORDER, 1) &&
               VerifyOffset(verifier, VT_DATA) &&
               verifier.VerifyVector(data()) && verifier.EndTable();
    }
};

struct TensorDataBuilder {
    typedef TensorData Table;
    ::flatbuffers::FlatBufferBuilder &fbb_;
    ::flatbuffers::uoffset_t start_;
    void add_name(::flatbuffers::Offset<::flatbuffers::String> name) {
        fbb_.AddOffset(TensorData::VT_NAME, name);
    }
    void add_dtype(axiom::io::fb::DType dtype) {
        fbb_.AddElement<int8_t>(TensorData::VT_DTYPE,
                                static_cast<int8_t>(dtype), 0);
    }
    void
    add_shape(::flatbuffers::Offset<::flatbuffers::Vector<uint64_t>> shape) {
        fbb_.AddOffset(TensorData::VT_SHAPE, shape);
    }
    void add_memory_order(axiom::io::fb::MemoryOrder memory_order) {
        fbb_.AddElement<int8_t>(TensorData::VT_MEMORY_ORDER,
                                static_cast<int8_t>(memory_order), 0);
    }
    void add_data(::flatbuffers::Offset<::flatbuffers::Vector<uint8_t>> data) {
        fbb_.AddOffset(TensorData::VT_DATA, data);
    }
    explicit TensorDataBuilder(::flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
        start_ = fbb_.StartTable();
    }
    ::flatbuffers::Offset<TensorData> Finish() {
        const auto end = fbb_.EndTable(start_);
        auto o = ::flatbuffers::Offset<TensorData>(end);
        return o;
    }
};

inline ::flatbuffers::Offset<TensorData> CreateTensorData(
    ::flatbuffers::FlatBufferBuilder &_fbb,
    ::flatbuffers::Offset<::flatbuffers::String> name = 0,
    axiom::io::fb::DType dtype = axiom::io::fb::DType_Bool,
    ::flatbuffers::Offset<::flatbuffers::Vector<uint64_t>> shape = 0,
    axiom::io::fb::MemoryOrder memory_order =
        axiom::io::fb::MemoryOrder_RowMajor,
    ::flatbuffers::Offset<::flatbuffers::Vector<uint8_t>> data = 0) {
    TensorDataBuilder builder_(_fbb);
    builder_.add_data(data);
    builder_.add_shape(shape);
    builder_.add_name(name);
    builder_.add_memory_order(memory_order);
    builder_.add_dtype(dtype);
    return builder_.Finish();
}

inline ::flatbuffers::Offset<TensorData>
CreateTensorDataDirect(::flatbuffers::FlatBufferBuilder &_fbb,
                       const char *name = nullptr,
                       axiom::io::fb::DType dtype = axiom::io::fb::DType_Bool,
                       const std::vector<uint64_t> *shape = nullptr,
                       axiom::io::fb::MemoryOrder memory_order =
                           axiom::io::fb::MemoryOrder_RowMajor,
                       const std::vector<uint8_t> *data = nullptr) {
    auto name__ = name ? _fbb.CreateString(name) : 0;
    auto shape__ = shape ? _fbb.CreateVector<uint64_t>(*shape) : 0;
    auto data__ = data ? _fbb.CreateVector<uint8_t>(*data) : 0;
    return axiom::io::fb::CreateTensorData(_fbb, name__, dtype, shape__,
                                           memory_order, data__);
}

struct TensorArchive FLATBUFFERS_FINAL_CLASS : private ::flatbuffers::Table {
    typedef TensorArchiveBuilder Builder;
    enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
        VT_VERSION = 4,
        VT_TENSORS = 6
    };
    uint32_t version() const { return GetField<uint32_t>(VT_VERSION, 2); }
    const ::flatbuffers::Vector<
        ::flatbuffers::Offset<axiom::io::fb::TensorData>> *
    tensors() const {
        return GetPointer<const ::flatbuffers::Vector<
            ::flatbuffers::Offset<axiom::io::fb::TensorData>> *>(VT_TENSORS);
    }
    template <bool B = false>
    bool Verify(::flatbuffers::VerifierTemplate<B> &verifier) const {
        return VerifyTableStart(verifier) &&
               VerifyField<uint32_t>(verifier, VT_VERSION, 4) &&
               VerifyOffset(verifier, VT_TENSORS) &&
               verifier.VerifyVector(tensors()) &&
               verifier.VerifyVectorOfTables(tensors()) && verifier.EndTable();
    }
};

struct TensorArchiveBuilder {
    typedef TensorArchive Table;
    ::flatbuffers::FlatBufferBuilder &fbb_;
    ::flatbuffers::uoffset_t start_;
    void add_version(uint32_t version) {
        fbb_.AddElement<uint32_t>(TensorArchive::VT_VERSION, version, 2);
    }
    void add_tensors(::flatbuffers::Offset<::flatbuffers::Vector<
                         ::flatbuffers::Offset<axiom::io::fb::TensorData>>>
                         tensors) {
        fbb_.AddOffset(TensorArchive::VT_TENSORS, tensors);
    }
    explicit TensorArchiveBuilder(::flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
        start_ = fbb_.StartTable();
    }
    ::flatbuffers::Offset<TensorArchive> Finish() {
        const auto end = fbb_.EndTable(start_);
        auto o = ::flatbuffers::Offset<TensorArchive>(end);
        return o;
    }
};

inline ::flatbuffers::Offset<TensorArchive> CreateTensorArchive(
    ::flatbuffers::FlatBufferBuilder &_fbb, uint32_t version = 2,
    ::flatbuffers::Offset<
        ::flatbuffers::Vector<::flatbuffers::Offset<axiom::io::fb::TensorData>>>
        tensors = 0) {
    TensorArchiveBuilder builder_(_fbb);
    builder_.add_tensors(tensors);
    builder_.add_version(version);
    return builder_.Finish();
}

inline ::flatbuffers::Offset<TensorArchive> CreateTensorArchiveDirect(
    ::flatbuffers::FlatBufferBuilder &_fbb, uint32_t version = 2,
    const std::vector<::flatbuffers::Offset<axiom::io::fb::TensorData>>
        *tensors = nullptr) {
    auto tensors__ =
        tensors
            ? _fbb.CreateVector<
                  ::flatbuffers::Offset<axiom::io::fb::TensorData>>(*tensors)
            : 0;
    return axiom::io::fb::CreateTensorArchive(_fbb, version, tensors__);
}

inline const axiom::io::fb::TensorArchive *GetTensorArchive(const void *buf) {
    return ::flatbuffers::GetRoot<axiom::io::fb::TensorArchive>(buf);
}

inline const axiom::io::fb::TensorArchive *
GetSizePrefixedTensorArchive(const void *buf) {
    return ::flatbuffers::GetSizePrefixedRoot<axiom::io::fb::TensorArchive>(
        buf);
}

inline const char *TensorArchiveIdentifier() { return "AXFB"; }

inline bool TensorArchiveBufferHasIdentifier(const void *buf) {
    return ::flatbuffers::BufferHasIdentifier(buf, TensorArchiveIdentifier());
}

inline bool SizePrefixedTensorArchiveBufferHasIdentifier(const void *buf) {
    return ::flatbuffers::BufferHasIdentifier(buf, TensorArchiveIdentifier(),
                                              true);
}

template <bool B = false>
inline bool
VerifyTensorArchiveBuffer(::flatbuffers::VerifierTemplate<B> &verifier) {
    return verifier.template VerifyBuffer<axiom::io::fb::TensorArchive>(
        TensorArchiveIdentifier());
}

template <bool B = false>
inline bool VerifySizePrefixedTensorArchiveBuffer(
    ::flatbuffers::VerifierTemplate<B> &verifier) {
    return verifier
        .template VerifySizePrefixedBuffer<axiom::io::fb::TensorArchive>(
            TensorArchiveIdentifier());
}

inline const char *TensorArchiveExtension() { return "axfb"; }

inline void FinishTensorArchiveBuffer(
    ::flatbuffers::FlatBufferBuilder &fbb,
    ::flatbuffers::Offset<axiom::io::fb::TensorArchive> root) {
    fbb.Finish(root, TensorArchiveIdentifier());
}

inline void FinishSizePrefixedTensorArchiveBuffer(
    ::flatbuffers::FlatBufferBuilder &fbb,
    ::flatbuffers::Offset<axiom::io::fb::TensorArchive> root) {
    fbb.FinishSizePrefixed(root, TensorArchiveIdentifier());
}

} // namespace fb
} // namespace io
} // namespace axiom

#endif // FLATBUFFERS_GENERATED_AXIOMTENSOR_AXIOM_IO_FB_H_
